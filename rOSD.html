<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>rOSD</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
	
  <style>
      .center{
        margin-left: auto;
        margin-right: auto;
      }
      .teaser{
        display: block;
        width: 70%;
        margin-top: 15px;
      }
      .paper-title{
        margin-top: 40px;
        font-size: 48px;
        text-align: center;
        width: 90%;
      }
      .author{
        padding-right: 50px;
        padding-left: 50px;
        margin-top: 15px;
        text-align: center;
        font-size: 18px;
      }
      .materials{
        margin-top: 20px;
        font-size: 18px;
        text-align: center;
        padding-right: 40px;
        padding-left: 40px;
      }
      .abstract{
        font-size: 16px;
        text-align: justify;
        width: 70%;
      }
  </style>
</head>
<body>
    <div class="container">
        <div class="row">
            <h1 class="paper-title center">
                Toward Unsupervised, Multi-Object Discovery in Large-Scale Image Collections
            </h1>
            <div>                
                <table class="author center" width="70%">
                    <tbody>
                        <tr>
                            <td class="author"><a href="https://huyvvo.github.io">Huy V. Vo</a><br>INRIA, Valeo.ai, ENS</td>
                            <td class="author"><a href="https://ptrckprz.github.io/">Patrick Pérez</a><br>Valeo.ai</td>
                            <td class="author"><a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a><br>INRIA</td>
                        </tr>
                    </tbody>
                </table>
                <div class="center">
                    <!-- <h3 style="text-align: center;" width="70%">Materials</h3> -->
                    <table class="materials center" width="70%" style="background-color: #90EE90; margin-top: 20px">
                        <tbody>
                            <tr>
                                <td class="materials"><a href="https://arxiv.org/pdf/2007.02662.pdf">Paper [ECCV 2020]</a></td>
                                <td class="materials"><a href="rOSD_slides.pdf">Slides</a></td>
                                <td class="materials"><a href="https://www.youtube.com/watch?v=v2vzEXOvUMs&t=19s">Video</a></td>
                                <td class="materials"><a href="https://github.com/huyvvo/rOSD">Code [Matlab]</a></td>
                            </tr>  
                        </tbody>  
                    </table>
                </div>
                <div class="abstract center">
                    <h3 style="text-align: center">Abstract</h3>
                    <p>
                        This paper addresses the problem of discovering the objects present in a collection of images without any supervision. We build on the optimization approach of Vo et al. (CVPR'19) with several key novelties: (1) We propose a novel saliency-based region proposal algorithm that achieves significantly higher overlap with ground-truth objects than other competitive methods. This procedure leverages off-the-shelf CNN features trained on classification tasks without any bounding box information, but is otherwise unsupervised. (2) We exploit the inherent hierarchical structure of proposals as an effective regularizer for the approach to object discovery of Vo et al., boosting its performance to significantly improve over the state of the art on several standard benchmarks. (3) We adopt a two-stage strategy to select promising proposals using small random sets of images before using the whole image collection to discover the objects it depicts, allowing us to tackle, for the first time (to the best of our knowledge), the discovery of multiple objects in each one of the pictures making up datasets with up to 20,000 images, an over five-fold increase compared to existing methods, and a first step toward true large-scale unsupervised image interpretation.
.
                    </p>
                </div>
                <img class="teaser center" src="img/rOSD_overview.jpg" alt=""> 
                <div class="center" style="text-align: justify; width: 70%">
                    <h3 style="text-align: center;">BibTex</h3>
                    <pre style="background-color: #e2e2e2; border: 1px dotted #818181; padding: 5px;">
@inproceedings{Vo20rOSD,
  title     = {Toward Unsupervised, Multi-Object Discovery in Large-Scale Image Collections},
  author    = {Vo, Huy V. and P{\'e}rez, Patrick and Ponce, Jean},
  booktitle = {Proceedings of the European Conference on Computer Vision ({ECCV})},
  year      = {2020}
}</pre>
                </div>
                <div class="center" style="text-align: justify; width: 70%">
                    <h3 style="text-align: center;">Acknowledgments</h3>
                    <p style="font-size: 16px;">
                        This work was supported in part by the Inria/NYU collaboration, the Louis Vuitton/ENS chair on artificial intelligence and the French government under management of Agence Nationale de la Recherche as part of the “Investissements d’avenir” program, reference ANR19-P3IA-0001 (PRAIRIE 3IA Institute). Huy V. Vo was supported in part by a Valeo/Prairie CIFRE PhD Fellowship.
                    </p>
                </div>
                <br><br><br>
            </div>
        </div>
    </div>
</body>
</html>